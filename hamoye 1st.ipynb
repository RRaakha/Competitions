{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n\ndf = pd.read_csv('/kaggle/input/food-balancesheets/FoodBalanceSheets_E_Africa_NOFLAG.csv', encoding = 'latin-1')\ndf.columns\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:17:23.467351Z","iopub.execute_input":"2023-09-28T08:17:23.467825Z","iopub.status.idle":"2023-09-28T08:17:23.663577Z","shell.execute_reply.started":"2023-09-28T08:17:23.467786Z","shell.execute_reply":"2023-09-28T08:17:23.662741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:20:30.045542Z","iopub.execute_input":"2023-09-28T08:20:30.045924Z","iopub.status.idle":"2023-09-28T08:20:30.072001Z","shell.execute_reply.started":"2023-09-28T08:20:30.045894Z","shell.execute_reply":"2023-09-28T08:20:30.071180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Area'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:24:30.743357Z","iopub.execute_input":"2023-09-28T08:24:30.743751Z","iopub.status.idle":"2023-09-28T08:24:30.762431Z","shell.execute_reply.started":"2023-09-28T08:24:30.743697Z","shell.execute_reply":"2023-09-28T08:24:30.761264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"madagascar_2015 = df[(df['Area'] == 'Madagascar') & (df['Y2015'])]\nmadagascar_2015","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:28:59.307057Z","iopub.execute_input":"2023-09-28T08:28:59.307445Z","iopub.status.idle":"2023-09-28T08:28:59.356395Z","shell.execute_reply.started":"2023-09-28T08:28:59.307413Z","shell.execute_reply":"2023-09-28T08:28:59.355633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame containing the data\n# Filter the DataFrame for the year 2014\ndata_2014 = df['Y2014']\n\n# Calculate the total number of missing values in the DataFrame for 2014\ntotal_missing_values = data_2014.isnull().sum().sum()\n\n# Calculate the total number of values in the DataFrame for 2014\ntotal_values = data_2014.size\n\n# Calculate the percentage of missing data\npercentage_missing = (total_missing_values / total_values) * 100\n\n# Print the results to 3 decimal places\nprint(\"Total number of missing values in 2014:\", total_missing_values)\nprint(\"Percentage of missing data in 2014 (to 3 decimal places): {:.3f}%\".format(percentage_missing))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:31:13.433332Z","iopub.execute_input":"2023-09-28T08:31:13.434472Z","iopub.status.idle":"2023-09-28T08:31:13.442456Z","shell.execute_reply.started":"2023-09-28T08:31:13.434422Z","shell.execute_reply":"2023-09-28T08:31:13.441260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame containing the data\n\n# Select the columns 'Y2017' and 'Area'\nselected_columns = df[['Y2017', 'Area']]\n\n# Group by 'Area' and sum the values for 'Y2017'\narea_sum_2017 = selected_columns.groupby('Area')['Y2017'].sum()\n\n# Sort the sums in ascending order and reset the index\nsorted_area_sum = area_sum_2017.reset_index().sort_values(by='Y2017')\n\n# Find the area with the 7th lowest sum in 2017\nseventh_lowest_area = sorted_area_sum.iloc[6]['Area']\n\nprint(\"Area with the 7th lowest sum in 2017:\", seventh_lowest_area)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:43:36.172055Z","iopub.execute_input":"2023-09-28T08:43:36.172460Z","iopub.status.idle":"2023-09-28T08:43:36.194687Z","shell.execute_reply.started":"2023-09-28T08:43:36.172427Z","shell.execute_reply":"2023-09-28T08:43:36.193302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame containing the data\n\n# Select the columns 'Y2017' and 'Area'\nselected_columns = df[['Y2017', 'Area']]\n\n# Group by 'Area' and sum the values for 'Y2017'\narea_sum_2017 = selected_columns.groupby('Area')['Y2017'].sum()\n\n# Find the area with the highest sum in 2017\narea_with_highest_sum_2017 = area_sum_2017.idxmax()\n\nprint(\"Area with the highest sum in 2017:\", area_with_highest_sum_2017)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:44:41.643011Z","iopub.execute_input":"2023-09-28T08:44:41.643416Z","iopub.status.idle":"2023-09-28T08:44:41.660611Z","shell.execute_reply.started":"2023-09-28T08:44:41.643382Z","shell.execute_reply":"2023-09-28T08:44:41.659075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame containing the data\n\n# Calculate the correlation between 'Element Code' and each year\ncorrelations = {}\nfor year in df[['Y2014','Y2015','Y2016','Y2017','Y2018']]:\n    correlation = df[df[['Y2014','Y2015','Y2016','Y2017','Y2018']] == year]['Element Code'].corr(df['Element Code'])\n    correlations[year] = abs(correlation)\n\n# Find the year with the least correlation\nleast_correlated_year = min(correlations, key=correlations.get)\n\nprint(\"Year with the least correlation with 'Element Code':\", least_correlated_year)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T08:49:34.849790Z","iopub.execute_input":"2023-09-28T08:49:34.850201Z","iopub.status.idle":"2023-09-28T08:49:35.220152Z","shell.execute_reply.started":"2023-09-28T08:49:34.850169Z","shell.execute_reply":"2023-09-28T08:49:35.219080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}